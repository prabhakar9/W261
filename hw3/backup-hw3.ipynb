{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASCI W261: Machine Learning at Scale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Name: Prabhakar Gundugola <br>\n",
    "Email: prabhakar@berkeley.edu <br>\n",
    "Time of Initial Submission: Feb 1, 2016 <br>\n",
    "W261-3: Spring 2016 <br>\n",
    "Week 3: Homework 3 <br>\n",
    "Date: February 1, 2016 <br>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HW3.0\n",
    "#### What is a merge sort? \n",
    "Merge sort is an efficient, general-purpose, comparison based sorting algorithm for rearranging lists into a specified order.\n",
    "\n",
    "![Mergesort algorithm](mergesort.png)\n",
    "\n",
    "Mergesort works as follows:\n",
    "- Divide the unsorted list into n sublists, each containing only 1 element.\n",
    "- Merge sublists repeatedly into sorted sublists until there is only 1 sublist remaining. \n",
    "\n",
    "**Where is it used in Hadoop?**\n",
    "Mergesort is used in sort and shuffle phase of hadoop between Map and Reduce phases.\n",
    "\n",
    "#### How is  a combiner function in the context of Hadoop?\n",
    "A combiner, also known as a semi-reducer, accepts the inputs from the Map procedure and thereafter passes the output of key,value pairs to the Reduce procedure.\n",
    "\n",
    "It is used in between Map and Reduce procedures to reduce the volume of data transfer between Map and Reduce when the output of Map phase is very large.\n",
    "\n",
    "![Combiner - Multiple reducers](combiner.PNG)\n",
    "\n",
    "#### Give an example where it can be used and justify why it should be used in the context of this problem.\n",
    "An example where a combiner is required is word count in large number of documents. A map emits a (key, value) pair with (word, 1) for each and every word in the document. The output of Map phase is very large and to reduce the volume of data transfer to reduce phase, we need a combiner that aggregates the values by key.\n",
    "\n",
    "#### What is the Hadoop shuffle?\n",
    "Hadoop shuffle is the process of transferring data from mappers to reducers based on a partitioning function. It sorts and combines all the data based on a partitioning key and ensures that all the (key, value) pairs of the same key are sent to the same reducer."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# HW 3.1. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
